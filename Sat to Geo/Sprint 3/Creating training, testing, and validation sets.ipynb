{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating training, testing, and validation sets\n",
    "\n",
    "In this notebook, we will create a training, testing, and validation sets for the data that has already been provided. An added feature is that the images used in the training and testing sets are completely separate from the images used in the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lawso\\AppData\\Local\\Continuum\\anaconda3\\envs\\geospatial\\lib\\site-packages\\skimage\\viewer\\utils\\__init__.py:1: UserWarning: Recommended matplotlib backend is `Agg` for full skimage.viewer functionality.\n",
      "  from .core import *\n"
     ]
    }
   ],
   "source": [
    "# Importing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as cx\n",
    "%matplotlib inline\n",
    "\n",
    "import math\n",
    "\n",
    "import os\n",
    "import urllib.request\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import random\n",
    "import skimage\n",
    "import skimage.feature\n",
    "import skimage.viewer\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is where you can specify what name you want to call it\n",
    "data_set_name = \"Split_Images_DM_Edge\"\n",
    "\n",
    "os.makedirs(\"Collected_Images/%s\" % (data_set_name), exist_ok=True)\n",
    "os.makedirs(\"Collected_Images/%s/test\" % (data_set_name), exist_ok=True)\n",
    "os.makedirs(\"Collected_Images/%s/val\" % (data_set_name), exist_ok=True)\n",
    "os.makedirs(\"Collected_Images/%s/train\" % (data_set_name), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed used: 6988439079880625549\n"
     ]
    }
   ],
   "source": [
    "# Seed used for this run for reproduceability\n",
    "seed = random.randrange(sys.maxsize)\n",
    "rand = random.Random(seed)\n",
    "print(\"Seed used:\", seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the images that we will be using\n",
    "f_set = [\n",
    "    \"Chihuahua_N\",\n",
    "    \"Colorodo\",\n",
    "    \"Idaho\",\n",
    "    \"Mid_Nevada\",\n",
    "    \"Mid_New_Mexico\",\n",
    "    \"N_Colorodo\",\n",
    "    \"New_Mexico_Franklin\",\n",
    "    \"S_Arizona\",\n",
    "    \"S_California\",\n",
    "    \"S_New_Mexico\",\n",
    "    \"S_Virginia\",\n",
    "    \"Tennessee\",\n",
    "    \"Texas\",\n",
    "    \"W_New_Mexico\",\n",
    "    \"W_Texas\",\n",
    "    \"W_Virginia\"\n",
    "]\n",
    "\n",
    "# Number of images that are going to be used for the validation set\n",
    "val_p = len(f_set) // 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of images that will be used for the testing set\n",
    "test_split = 0.2\n",
    "\n",
    "# Total number of testing and training sets\n",
    "num_tt_imgs = 1200\n",
    "\n",
    "# Total number of validation sets\n",
    "num_val_imgs = 200\n",
    "\n",
    "# The size of the subplot images that will be used for \n",
    "# testing/training/validation\n",
    "img_size = 256\n",
    "\n",
    "# The size of the input image\n",
    "input_size = 880\n",
    "\n",
    "# If you want the resulting formation image to be grayscale\n",
    "greyscale = False\n",
    "\n",
    "# If you want the resulting formation image to be run through edge\n",
    "# detection\n",
    "edge = True\n",
    "\n",
    "# Where to pull the GAN images from (GAN refers to Satellite images on the\n",
    "# left and the corresponding Formation image on the right)\n",
    "src_path = \"Collected_Images/DM_Dataset/GAN_pics/\"\n",
    "\n",
    "# Save paths from the training, testing and validation sets\n",
    "paths = [\n",
    "    \"Collected_Images/%s/train/\" % (data_set_name),\n",
    "    \"Collected_Images/%s/test/\" % (data_set_name),\n",
    "    \"Collected_Images/%s/val/\" % (data_set_name)\n",
    "]\n",
    "\n",
    "# A total count of the number of testing and training images.\n",
    "n_vals = [\n",
    "    int(num_tt_imgs * (1 - test_split)),\n",
    "    int(num_tt_imgs * (test_split))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An array containing the names of the images used for the validation set\n",
    "v_set = []\n",
    "\n",
    "# Picking out val_p random images to hold off from the original set to use\n",
    "# for the validation set.\n",
    "for i in range(0, val_p):\n",
    "    choice = rand.randrange(0, len(f_set))\n",
    "    v_set.append(f_set[choice])\n",
    "    f_set.remove(f_set[choice])\n",
    "\n",
    "# All remaining images are used for the training and testing sets    \n",
    "tt_set = f_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['W_Texas', 'Mid_Nevada', 'Colorodo', 'S_Virginia']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Images that will make up the validation set in this notebook\n",
    "v_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chihuahua_N',\n",
       " 'Idaho',\n",
       " 'Mid_New_Mexico',\n",
       " 'N_Colorodo',\n",
       " 'New_Mexico_Franklin',\n",
       " 'S_Arizona',\n",
       " 'S_California',\n",
       " 'S_New_Mexico',\n",
       " 'Tennessee',\n",
       " 'Texas',\n",
       " 'W_New_Mexico',\n",
       " 'W_Virginia']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Images that will make up the testing and training set \n",
    "# in this notebook\n",
    "tt_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing training and testing sets\n",
    "\n",
    "It does not matter which sets we will construct first considering how the validation set and the training and testing sets are completely separate from each other. However here, we will be constructing the training and testing sets first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array of dictionaries to ensure there are no repeated plots\n",
    "# But there is no protection about overlapping subplots\n",
    "visited = []\n",
    "\n",
    "for i in range(0, num_tt_imgs):\n",
    "    \n",
    "    # First select a image to pull from,\n",
    "    # the x coordinate for the subplot,\n",
    "    # and the y coordinate for the subplot\n",
    "    src = rand.randrange(0, len(tt_set))\n",
    "    x = rand.randrange(0,input_size - img_size)\n",
    "    y = rand.randrange(0,input_size - img_size)\n",
    "    \n",
    "    # Establish it as a dictionary\n",
    "    cord = {\n",
    "        \"source\": src,\n",
    "        \"x_cord\": x,\n",
    "        \"y_cord\": y,\n",
    "    }\n",
    "    \n",
    "    # Lastly, make sure that we have not already looked at this\n",
    "    # plot. If we have already looked at it, then we pick out a new\n",
    "    # plot.\n",
    "    while(cord in visited):\n",
    "        src = rand.randrange(0, len(tt_set))\n",
    "        x = rand.randrange(0,input_size - img_size)\n",
    "        y = rand.randrange(0,input_size - img_size)\n",
    "\n",
    "        cord = {\n",
    "            \"source\": src,\n",
    "            \"x_cord\": x,\n",
    "            \"y_cord\": y,\n",
    "        }\n",
    "    \n",
    "    # At this point we have a new unvisited plot, so we append it to\n",
    "    # the list of visited plots and continue.\n",
    "    visited.append(cord)\n",
    "    \n",
    "    # Next, pull the GAN image and split it into it's Satellite and\n",
    "    # Formation image.\n",
    "    img = Image.open(src_path + tt_set[src] + \"-gan.png\")\n",
    "    \n",
    "    # Next, we make sure to crop out a subplot of the desired \n",
    "    # from the original image given the randomized x and y cordinates. \n",
    "    # For this we need to make sure we get the subplot of the \n",
    "    # satellite and the formation image.\n",
    "    left = x\n",
    "    top = y\n",
    "    right = left + img_size\n",
    "    bottom = top + img_size\n",
    "    \n",
    "    # This image is the Satellite image\n",
    "    lft_img = img.crop((left,\n",
    "                        top,\n",
    "                        right,\n",
    "                        bottom))\n",
    "    \n",
    "    # This image is the Formation image\n",
    "    rht_img = img.crop((left+input_size,\n",
    "                        top,\n",
    "                        right+input_size,\n",
    "                        bottom))\n",
    "    \n",
    "    # Next come the special cases.\n",
    "    \n",
    "    # Run the Formation image through cv2's Canny to get edge detection\n",
    "    if(edge):\n",
    "        rht_img.save(src_path + \"temp_rht_img.png\")\n",
    "        \n",
    "        img = cv2.imread(src_path + \"temp_rht_img.png\")\n",
    "        edges = cv2.Canny(img,100,200)\n",
    "        \n",
    "        rht_img = Image.fromarray(edges)    \n",
    "    \n",
    "    # Run the Formation image through skimage to greyscale the image\n",
    "    if(greyscale):\n",
    "        rht_img.save(src_path + \"temp_rht_img.png\")\n",
    "\n",
    "        temp_rht_img = skimage.io.imread(fname = src_path + \"temp_rht_img.png\")\n",
    "        temp_ar = np.copy(temp_rht_img)\n",
    "        x_ar = temp_ar  \n",
    "        result = x_ar[:, :, 2]\n",
    "        result = result * (1.0/255.0)\n",
    "        skimage.io.imsave(arr = result, fname = src_path + \"temp_rht_g_img.png\")\n",
    "\n",
    "        rht_img = Image.open(src_path + \"temp_rht_g_img.png\")\n",
    "    \n",
    "    \n",
    "    # Lastly, join the satellite subplot image and the formation subplot image\n",
    "    # and save it off to the correct path.\n",
    "    joint = Image.new(\"RGB\", (lft_img.width + rht_img.width, lft_img.height))\n",
    "    joint.paste(lft_img, (0,0))\n",
    "    joint.paste(rht_img, (lft_img.width, 0))\n",
    "    \n",
    "    \n",
    "    # Choose a random number to signify whether the current image will be saved\n",
    "    # to the training or the testing set.\n",
    "    r = rand.randrange(0,2)\n",
    "    choice = n_vals[r]\n",
    "    \n",
    "    # However, if the number in the given set has already reached capacity\n",
    "    # i.e. We have already generated enough images for the testing set, we\n",
    "    # need to save it into the training set.\n",
    "    if(choice == 0):\n",
    "        r = abs(r - 1)\n",
    "    \n",
    "    n_vals[r] -= 1\n",
    "    \n",
    "    # Save off the image into the correct path.\n",
    "    joint.save(paths[r] + str(i) + \"-\" + tt_set[src] + \"-img.png\")\n",
    "\n",
    "# Lastly, if any of the special techniques were used, then clean up any\n",
    "# extra images that were generated.\n",
    "if(greyscale or edge):\n",
    "    os.remove(src_path + \"temp_rht_img.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the validation set\n",
    "\n",
    "The next segment of code is almost exactly the same as the code used for constructing the training and testing set. So, I'll just comment the change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "visited = []\n",
    "\n",
    "for i in range(0, num_val_imgs):\n",
    "    src = rand.randrange(0, len(v_set))\n",
    "    x = rand.randrange(0,input_size - img_size)\n",
    "    y = rand.randrange(0,input_size - img_size)\n",
    "    \n",
    "    cord = {\n",
    "        \"source\": src,\n",
    "        \"x_cord\": x,\n",
    "        \"y_cord\": y,\n",
    "    }\n",
    "    \n",
    "    while(cord in visited):\n",
    "        src = rand.randrange(0, len(v_set))\n",
    "        x = rand.randrange(0,input_size - img_size)\n",
    "        y = rand.randrange(0,input_size - img_size)\n",
    "\n",
    "        cord = {\n",
    "            \"source\": src,\n",
    "            \"x_cord\": x,\n",
    "            \"y_cord\": y,\n",
    "        }\n",
    "    \n",
    "    visited.append(cord)\n",
    "    \n",
    "    img = Image.open(src_path + v_set[src] + \"-gan.png\")\n",
    "    \n",
    "    left = x\n",
    "    top = y\n",
    "    right = left + img_size\n",
    "    bottom = top + img_size\n",
    "    \n",
    "    lft_img = img.crop((left,\n",
    "                        top,\n",
    "                        right,\n",
    "                        bottom))\n",
    "    \n",
    "    rht_img = img.crop((left+input_size,\n",
    "                        top,\n",
    "                        right+input_size,\n",
    "                        bottom))\n",
    "    \n",
    "    if(edge):\n",
    "        rht_img.save(src_path + \"temp_rht_img.png\")\n",
    "        \n",
    "        img = cv2.imread(src_path + \"temp_rht_img.png\")\n",
    "        edges = cv2.Canny(img,100,200)\n",
    "        rht_img = Image.fromarray(edges)\n",
    "    \n",
    "    \n",
    "    if(greyscale):\n",
    "        rht_img.save(src_path + \"temp_rht_img.png\")\n",
    "\n",
    "        temp_rht_img = skimage.io.imread(fname = src_path + \"temp_rht_img.png\")\n",
    "        temp_ar = np.copy(temp_rht_img)\n",
    "        x_ar = temp_ar  \n",
    "        result = x_ar[:, :, 2]\n",
    "        result = result * (1.0/255.0)\n",
    "        skimage.io.imsave(arr = result, fname = src_path + \"temp_rht_g_img.png\")\n",
    "\n",
    "        rht_img = Image.open(src_path + \"temp_rht_g_img.png\")\n",
    "    \n",
    "    # The only thing that has changed is that there is no need to worry about\n",
    "    # where to save it, as there is only one validation set.\n",
    "    \n",
    "    joint = Image.new(\"RGB\", (lft_img.width + rht_img.width, lft_img.height))\n",
    "    joint.paste(lft_img, (0,0))\n",
    "    joint.paste(rht_img, (lft_img.width, 0))\n",
    "    \n",
    "    joint.save(paths[2] + str(i) + \"-\" + v_set[src] + \"-img.png\")\n",
    "    \n",
    "if(greyscale or edge):\n",
    "    os.remove(src_path + \"temp_rht_img.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
